{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (sys.version_info[0]==3 and sys.version_info[1]>=8):\n",
    "    raise Exception('Must be Python 3.8 or above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_PATH = 'users'\n",
    "VIDEO_DIR_NAME = 'videos'\n",
    "VIDEO_VEC_DIR_NAME = 'video_vectors'\n",
    "COLLECTION_NAME = \"vector_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user(user_name, collection = COLLECTION_NAME):\n",
    "    if user_name not in os.listdir(USERS_PATH):\n",
    "        os.mkdir('/'.join([USERS_PATH, user_name]))\n",
    "    if VIDEO_DIR_NAME not in os.listdir('/'.join([USERS_PATH, user_name])):\n",
    "        os.mkdir('/'.join([USERS_PATH, user_name, VIDEO_DIR_NAME]))\n",
    "    if VIDEO_VEC_DIR_NAME not in os.listdir('/'.join([USERS_PATH, user_name])):\n",
    "        os.mkdir('/'.join([USERS_PATH, user_name, VIDEO_VEC_DIR_NAME]))\n",
    "    client = QdrantClient(path='users/test_user/db')\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection,\n",
    "        vectors_config=models.VectorParams(size=1024, distance=models.Distance.COSINE)\n",
    "    )\n",
    "    return client\n",
    "\n",
    "def create_raw_vector_file(input_file, output_file):\n",
    "    command = [\n",
    "                \"conda/bin/python3.7\",\n",
    "                \"video_embedding/video2vec.py\",\n",
    "                \"--graph_file\", \"./Models/inception-v3_image_classify_graph_def.pb\",\n",
    "                \"--fcnn_model\", \"./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\",\n",
    "                \"--input_file\", input_file,\n",
    "                \"--output_file\", output_file\n",
    "            ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "def process_raw_vector(raw_vector):\n",
    "    vector = raw_vector.split(',')[-1].split('_')\n",
    "    vector = np.array([float(x) for x in vector])\n",
    "    return vector\n",
    "\n",
    "def add_one_vector_to_bd(processed_vector,\n",
    "                         video_name,\n",
    "                         client,\n",
    "                         collection = COLLECTION_NAME):\n",
    "    amount_of_vectors = client.count(\n",
    "    collection_name=collection, \n",
    "    exact=True,\n",
    "    ).count\n",
    "    client.upsert(\n",
    "        collection_name=collection,\n",
    "        points=models.Batch(\n",
    "            ids=[amount_of_vectors],\n",
    "            vectors=[processed_vector],\n",
    "            payloads=[{'source': video_name}]\n",
    "        )\n",
    "    )\n",
    "\n",
    "def calc_vector(video_name, \n",
    "                user_name,\n",
    "                client, \n",
    "                collection = COLLECTION_NAME,\n",
    "                users_path = USERS_PATH, \n",
    "                video_dir_name = VIDEO_DIR_NAME, \n",
    "                video_vec_dir_name = VIDEO_VEC_DIR_NAME):\n",
    "    input_file = '/'.join(['.', users_path, user_name, video_dir_name, video_name])\n",
    "    output_file = '/'.join(['.', users_path, user_name, video_vec_dir_name, '.'.join(video_name.split('.')[:-1])])\n",
    "    create_raw_vector_file(input_file, output_file)\n",
    "    processed_vector = process_raw_vector(open(output_file, 'r').readline())\n",
    "    add_one_vector_to_bd(processed_vector, video_name, client, collection)\n",
    "\n",
    "def calc_vector_and_get_closest(video_name, \n",
    "                                user_name,\n",
    "                                client, \n",
    "                                collection = COLLECTION_NAME,\n",
    "                                users_path = USERS_PATH, \n",
    "                                video_dir_name = VIDEO_DIR_NAME, \n",
    "                                video_vec_dir_name = VIDEO_VEC_DIR_NAME,\n",
    "                                limit = 5):\n",
    "    input_file = '/'.join(['.', users_path, user_name, video_dir_name, video_name])\n",
    "    output_file = '/'.join(['.', users_path, user_name, video_vec_dir_name, '.'.join(video_name.split('.')[:-1])])\n",
    "    create_raw_vector_file(input_file, output_file)\n",
    "    processed_vector = process_raw_vector(open(output_file, 'r').readline())\n",
    "    return client.search(\n",
    "    collection_name=collection,\n",
    "    query_vector=processed_vector,\n",
    "    limit=limit\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = 'test_user'\n",
    "\n",
    "all_users = {}\n",
    "all_users['user_name'] = create_user(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_name in os.listdir('Videos/'):\n",
    "    shutil.copyfile(f'Videos/{video_name}', '/'.join([USERS_PATH, user_name, VIDEO_DIR_NAME, video_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_name in os.listdir('/'.join([USERS_PATH, user_name, VIDEO_DIR_NAME])):\n",
    "    calc_vector(video_name,\n",
    "                user_name,\n",
    "                all_users['user_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From video_embedding/video2vec.py:99: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:99: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:100: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:44: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "W0403 14:11:03.317576 140650387453760 deprecation.py:323] From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:44: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:45: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "W0403 14:11:03.317660 140650387453760 module_wrapper.py:139] From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:45: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "2024-04-03 14:11:03.456132: W tensorflow/core/framework/op_def_util.cc:357] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0403 14:11:03.518651 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow: Create graph from \"./Models/inception-v3_image_classify_graph_def.pb\"\n",
      "I0403 14:11:03.518801 140650387453760 video2vec.py:36]  Create graph from \"./Models/inception-v3_image_classify_graph_def.pb\"\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0403 14:11:03.518862 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2024-04-03 14:11:03.519105: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 14:11:03.523173: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2918400000 Hz\n",
      "2024-04-03 14:11:03.525500: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555fc8c72390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-03 14:11:03.525530: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-19\n",
      "OMP: Info #156: KMP_AFFINITY: 20 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 10 cores/pkg x 2 threads/core (10 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 4 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 4 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 5 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 5 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 6 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 6 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 7 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 7 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 8 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 8 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 9 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 9 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287021 thread 0 bound to OS proc set 0\n",
      "2024-04-03 14:11:03.528420: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287112 thread 1 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287170 thread 2 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287171 thread 3 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287172 thread 4 bound to OS proc set 8\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287173 thread 5 bound to OS proc set 10\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287174 thread 6 bound to OS proc set 12\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287175 thread 7 bound to OS proc set 14\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287176 thread 8 bound to OS proc set 16\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287177 thread 9 bound to OS proc set 18\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287178 thread 10 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287179 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287181 thread 13 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287182 thread 14 bound to OS proc set 9\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287183 thread 15 bound to OS proc set 11\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287184 thread 16 bound to OS proc set 13\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287180 thread 12 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287185 thread 17 bound to OS proc set 15\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287186 thread 18 bound to OS proc set 17\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287188 thread 20 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287187 thread 19 bound to OS proc set 19\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287111 thread 21 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287190 thread 23 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287189 thread 22 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287191 thread 24 bound to OS proc set 8\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287192 thread 25 bound to OS proc set 10\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287193 thread 26 bound to OS proc set 12\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287194 thread 27 bound to OS proc set 14\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287195 thread 28 bound to OS proc set 16\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287197 thread 30 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287199 thread 32 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287198 thread 31 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287196 thread 29 bound to OS proc set 18\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287200 thread 33 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287202 thread 35 bound to OS proc set 11\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287201 thread 34 bound to OS proc set 9\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287203 thread 36 bound to OS proc set 13\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287204 thread 37 bound to OS proc set 15\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287206 thread 39 bound to OS proc set 19\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287205 thread 38 bound to OS proc set 17\n",
      "OMP: Info #250: KMP_AFFINITY: pid 287021 tid 287207 thread 40 bound to OS proc set 0\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:56: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0403 14:11:12.469856 140650387453760 module_wrapper.py:139] From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:56: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0403 14:11:12.499688 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:113: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0403 14:11:12.501193 140650387453760 module_wrapper.py:139] From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:113: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:52: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0403 14:11:12.509911 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:52: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:52: The name tf.train.SaverDef is deprecated. Please use tf.compat.v1.train.SaverDef instead.\n",
      "\n",
      "W0403 14:11:12.510045 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:52: The name tf.train.SaverDef is deprecated. Please use tf.compat.v1.train.SaverDef instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:53: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0403 14:11:12.517369 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:53: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:53: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W0403 14:11:12.517934 140650387453760 module_wrapper.py:139] From video_embedding/video2vec.py:53: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0, FramConvLayer | Conv HWIO,S = [4,1,1,32],1; Pooling HW,S = [2, 1],2\n",
      "Layer 1, FramConvLayer | Conv HWIO,S = [4,1,32,16],1; Pooling HW,S = [2, 1],2\n",
      "Layer 2, FramConvLayer | Conv HWIO,S = [3,1,16,8],1; Pooling HW,S = [2, 1],2\n",
      "Layer 3, FramConvLayer | Conv HWIO,S = [3,1,8,4],1; Pooling HW,S = [2, 1],2\n",
      "Layer 4, FramConvLayer | Conv HWIO,S = [2,1,4,2],1; Pooling HW,S = [2, 1],2\n",
      "Layer 5, FramConvLayer | Conv HWIO,S = [2,1,2,1],1; Pooling HW,S = [2, 1],2\n",
      "Layer 6, DenseConnLayer | IO = [2048,1024]\n",
      "Layer 7, SoftmaxLayer | IO = [1024,28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\n",
      "I0403 14:11:12.724215 140650387453760 saver.py:1284] Restoring parameters from ./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\n",
      "INFO:tensorflow: Restoring model from \"./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\"\n",
      "I0403 14:11:12.855102 140650387453760 video2vec.py:55]  Restoring model from \"./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\"\n",
      "INFO:tensorflow: Done!! Please check \"./users/test_user_2/video_vectors/cars_part\"\n",
      "I0403 14:11:13.053834 140650387453760 video2vec.py:93]  Done!! Please check \"./users/test_user_2/video_vectors/cars_part\"\n"
     ]
    }
   ],
   "source": [
    "search_result = calc_vector_and_get_closest('cars_part.mp4',\n",
    "                                        user_name,\n",
    "                                        all_users['user_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScoredPoint(id=5, version=0, score=0.7638798476612538, payload={'source': 'cars.mp4'}, vector=None, shard_key=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match:cars.mp4 0.7638798476612538\n",
      "Closest matches: \n",
      "bugatti.mp4 \tScore: 0.6636374241685357\n",
      "old_car.mp4 \tScore: 0.5222012856200975\n",
      "flowers.mp4 \tScore: 0.5186204743832249\n",
      "news_car.mp4 \tScore: 0.4982871169034968\n"
     ]
    }
   ],
   "source": [
    "print('Best match:'+search_result[0].payload['source'], search_result[0].score)\n",
    "print('Closest matches: ')\n",
    "for result in search_result[1:]:\n",
    "    print(result.payload['source'], '\\tScore:', result.score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_vectors = all_users['user_name'].count(\n",
    "    collection_name=COLLECTION_NAME, \n",
    "    exact=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount_of_vectors.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From video_embedding/video2vec.py:99: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:99: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:100: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:44: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "W0403 11:52:42.218444 140081366599488 deprecation.py:323] From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:44: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:45: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "W0403 11:52:42.218548 140081366599488 module_wrapper.py:139] From /home/alex/video_embedding/video_embedding/embedding/image_embedding.py:45: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "2024-04-03 11:52:42.371873: W tensorflow/core/framework/op_def_util.cc:357] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0403 11:52:42.438078 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow: Create graph from \"./Models/inception-v3_image_classify_graph_def.pb\"\n",
      "I0403 11:52:42.438395 140081366599488 video2vec.py:36]  Create graph from \"./Models/inception-v3_image_classify_graph_def.pb\"\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0403 11:52:42.438477 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2024-04-03 11:52:42.438748: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-03 11:52:42.442208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2918400000 Hz\n",
      "2024-04-03 11:52:42.443477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f2efc50f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-03 11:52:42.443499: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-19\n",
      "OMP: Info #156: KMP_AFFINITY: 20 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 10 cores/pkg x 2 threads/core (10 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 4 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 4 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 5 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 5 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 6 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 6 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 7 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 7 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 8 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 8 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 9 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 9 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168030 thread 0 bound to OS proc set 0\n",
      "2024-04-03 11:52:42.444469: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168115 thread 1 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168186 thread 2 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168187 thread 3 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168188 thread 4 bound to OS proc set 8\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168189 thread 5 bound to OS proc set 10\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168190 thread 6 bound to OS proc set 12\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168191 thread 7 bound to OS proc set 14\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168192 thread 8 bound to OS proc set 16\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168197 thread 13 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168194 thread 10 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168199 thread 15 bound to OS proc set 11\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168195 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168198 thread 14 bound to OS proc set 9\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168193 thread 9 bound to OS proc set 18\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168196 thread 12 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168200 thread 16 bound to OS proc set 13\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168203 thread 19 bound to OS proc set 19\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168201 thread 17 bound to OS proc set 15\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168202 thread 18 bound to OS proc set 17\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168204 thread 20 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168114 thread 21 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168205 thread 22 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168206 thread 23 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168208 thread 25 bound to OS proc set 10\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168207 thread 24 bound to OS proc set 8\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168209 thread 26 bound to OS proc set 12\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168210 thread 27 bound to OS proc set 14\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168211 thread 28 bound to OS proc set 16\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168212 thread 29 bound to OS proc set 18\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168214 thread 31 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168213 thread 30 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168215 thread 32 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168218 thread 35 bound to OS proc set 11\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168217 thread 34 bound to OS proc set 9\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168216 thread 33 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168219 thread 36 bound to OS proc set 13\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168220 thread 37 bound to OS proc set 15\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168221 thread 38 bound to OS proc set 17\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168222 thread 39 bound to OS proc set 19\n",
      "OMP: Info #250: KMP_AFFINITY: pid 168030 tid 168223 thread 40 bound to OS proc set 0\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:56: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0403 11:52:51.520242 140081366599488 module_wrapper.py:139] From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:56: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0403 11:52:51.556090 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:113: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0403 11:52:51.557343 140081366599488 module_wrapper.py:139] From /home/alex/video_embedding/video_embedding/embedding/fcnn.py:113: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:52: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0403 11:52:51.565389 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:52: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:52: The name tf.train.SaverDef is deprecated. Please use tf.compat.v1.train.SaverDef instead.\n",
      "\n",
      "W0403 11:52:51.565524 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:52: The name tf.train.SaverDef is deprecated. Please use tf.compat.v1.train.SaverDef instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:53: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "W0403 11:52:51.572747 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:53: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From video_embedding/video2vec.py:53: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W0403 11:52:51.573358 140081366599488 module_wrapper.py:139] From video_embedding/video2vec.py:53: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0, FramConvLayer | Conv HWIO,S = [4,1,1,32],1; Pooling HW,S = [2, 1],2\n",
      "Layer 1, FramConvLayer | Conv HWIO,S = [4,1,32,16],1; Pooling HW,S = [2, 1],2\n",
      "Layer 2, FramConvLayer | Conv HWIO,S = [3,1,16,8],1; Pooling HW,S = [2, 1],2\n",
      "Layer 3, FramConvLayer | Conv HWIO,S = [3,1,8,4],1; Pooling HW,S = [2, 1],2\n",
      "Layer 4, FramConvLayer | Conv HWIO,S = [2,1,4,2],1; Pooling HW,S = [2, 1],2\n",
      "Layer 5, FramConvLayer | Conv HWIO,S = [2,1,2,1],1; Pooling HW,S = [2, 1],2\n",
      "Layer 6, DenseConnLayer | IO = [2048,1024]\n",
      "Layer 7, SoftmaxLayer | IO = [1024,28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\n",
      "I0403 11:52:51.782610 140081366599488 saver.py:1284] Restoring parameters from ./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\n",
      "INFO:tensorflow: Restoring model from \"./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\"\n",
      "I0403 11:52:51.915764 140081366599488 video2vec.py:55]  Restoring model from \"./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\"\n",
      "INFO:tensorflow: Done!! Please check \"./cars_part_v\"\n",
      "I0403 11:52:52.123811 140081366599488 video2vec.py:93]  Done!! Please check \"./cars_part_v\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['conda/bin/python3.7', 'video_embedding/video2vec.py', '--graph_file', './Models/inception-v3_image_classify_graph_def.pb', '--fcnn_model', './Models/weibo_MCN_14k_frames30_sfps1.ckpt-done', '--input_file', './Videos/cars_part.mp4', '--output_file', './cars_part_v'], returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conda/bin/python3.7 video_embedding/video2vec.py --graph_file ./Models/inception-v3_image_classify_graph_def.pb --fcnn_model ./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done --input_file ./Videos/cars_part.mp4 --output_file ./cars_part_v\n",
    "command = [\n",
    "                \"conda/bin/python3.7\",\n",
    "                \"video_embedding/video2vec.py\",\n",
    "                \"--graph_file\", \"./Models/inception-v3_image_classify_graph_def.pb\",\n",
    "                \"--fcnn_model\", \"./Models/weibo_MCN_14k_frames30_sfps1.ckpt-done\",\n",
    "                \"--input_file\", \"./Videos/cars_part.mp4\",\n",
    "                \"--output_file\", \"./cars_part_v\"\n",
    "            ]\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vide_vectors_path = 'Video_vectors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_vectors = {}\n",
    "for video_vector in os.listdir(vide_vectors_path):\n",
    "    processed_vectors[video_vector] = process_raw_vector(open(vide_vectors_path+video_vector, 'r').readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.DataFrame({'source': list(processed_vectors.keys()), 'embedding': list(processed_vectors.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flowers_v</td>\n",
       "      <td>[0.247657, 0.355781, -0.0, 0.827153, 0.631797,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_v</td>\n",
       "      <td>[-0.0, -0.0, 0.499744, -0.0, -0.0, -0.0, -0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cars_v</td>\n",
       "      <td>[0.644818, -0.0, -0.0, -0.0, 0.933452, -0.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cars_part_v</td>\n",
       "      <td>[0.045901, 0.622638, -0.0, -0.0, -0.0, -0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                          embedding\n",
       "0    flowers_v  [0.247657, 0.355781, -0.0, 0.827153, 0.631797,...\n",
       "1       city_v  [-0.0, -0.0, 0.499744, -0.0, -0.0, -0.0, -0.0,...\n",
       "2       cars_v  [0.644818, -0.0, -0.0, -0.0, 0.933452, -0.0, -...\n",
       "3  cars_part_v  [0.045901, 0.622638, -0.0, -0.0, -0.0, -0.0, 0..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(path='users/test_user/db')\n",
    "my_collection = \"vector_collection\"\n",
    "client.recreate_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=1024, distance=models.Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.247657,  0.355781, -0.      , ..., -0.      , -0.      ,\n",
       "         0.163055]),\n",
       " array([-0.      , -0.      ,  0.499744, ...,  1.191377, -0.      ,\n",
       "        -0.      ]),\n",
       " array([ 0.644818, -0.      , -0.      , ..., -0.      , -0.      ,\n",
       "         1.191729]),\n",
       " array([ 0.045901,  0.622638, -0.      , ..., -0.      , -0.      ,\n",
       "        -0.      ])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors['embedding'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "        collection_name=my_collection,\n",
    "        points=models.Batch(\n",
    "            ids=list(range(len(vectors))),\n",
    "            vectors=vectors['embedding'].values.tolist(),\n",
    "            payloads=[{'source': i} for i in vectors['source'].values.tolist()]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.count(\n",
    "    collection_name=my_collection, \n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Record(id=0, payload={'source': 'flowers_v'}, vector=None, shard_key=None),\n",
       "  Record(id=1, payload={'source': 'city_v'}, vector=None, shard_key=None),\n",
       "  Record(id=2, payload={'source': 'cars_v'}, vector=None, shard_key=None),\n",
       "  Record(id=3, payload={'source': 'cars_part_v'}, vector=None, shard_key=None)],\n",
       " None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.scroll(\n",
    "    collection_name=my_collection,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=3, version=0, score=0.9999999970113996, payload={'source': 'cars_part_v'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=2, version=0, score=0.7638798476612538, payload={'source': 'cars_v'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=0, version=0, score=0.518620474383225, payload={'source': 'flowers_v'}, vector=None, shard_key=None),\n",
       " ScoredPoint(id=1, version=0, score=0.4860995158778002, payload={'source': 'city_v'}, vector=None, shard_key=None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=vectors['embedding'].values.tolist()[3],\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_similarity(v_1, v_2):\n",
    "#     return np.dot(v_1,v_2)/(np.linalg.norm(v_1)*np.linalg.norm(v_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Car Full -- Car Clip:\\t\\t',cosine_similarity(vector_cars, vector_cars_part))\n",
    "# print('Flowers Full -- Car Clip:\\t',cosine_similarity(vector_flowers, vector_cars_part))\n",
    "# print('City Full  -- Car Clip:\\t\\t',cosine_similarity(vector_city, vector_cars_part))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
